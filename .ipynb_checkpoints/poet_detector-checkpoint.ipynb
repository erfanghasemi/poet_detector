{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}\n",
    "\n",
    "# This function creates a dictionary from whole distinct words of a text file.\n",
    "\n",
    "line = None\n",
    "count  = 0\n",
    "def update_dict(file_path: str):\n",
    "    global count, line, words\n",
    "    with open(file_path, 'r', encoding='UTF_8') as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            for word in line.split():\n",
    "                if word not in words:\n",
    "                    words[word] = 1\n",
    "                else:\n",
    "                    words[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_dict('ferdowsi_train.txt')\n",
    "update_dict('hafez_train.txt')\n",
    "update_dict('molavi_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for word in words:\n",
    "    if words[word] < 2:\n",
    "        temp.append(word)\n",
    "for word in temp:\n",
    "    del words[word]\n",
    "words[\"<s>\"] = 1\n",
    "words[\"</s>\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This function receives a text file path. All words shared between\n",
    "the text file and words dictionary, count occurrences of each word,\n",
    "and then create the unigram model by calculating the independent occurrence probability.\n",
    "\"\"\"\n",
    "\n",
    "def unigram(file_path: str):\n",
    "    global words\n",
    "    lines_count = 0\n",
    "    total_words = 0\n",
    "    prob_dict = {}\n",
    "    with open(file_path, 'r', encoding='UTF_8') as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            lines_count += 1\n",
    "            for word in line.split():\n",
    "                total_words += 1\n",
    "                if word in words:\n",
    "                    if word in prob_dict:\n",
    "                        prob_dict[word] += 1\n",
    "                    else:\n",
    "                        prob_dict[word] = 1\n",
    "                else:\n",
    "                    prob_dict[word] = 0\n",
    "    words_count = deepcopy(prob_dict)\n",
    "    for word in prob_dict:\n",
    "        prob_dict[word] /= total_words\n",
    "    \n",
    "    prob_dict[\"</s>\"] = lines_count / total_words\n",
    "    return prob_dict, lines_count, words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ferdowsi_unigram, ferdowsi_lines, ferdowsi_words = unigram('ferdowsi_train.txt')\n",
    "hafez_unigram, hafez_lines, hafez_words = unigram('hafez_train.txt')\n",
    "moalvi_unigram, molavi_lines, molavi_words = unigram('molavi_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This function receives a text file path, count of text's lines,\n",
    "and count of each word's occurrence. Counts the occurrence of each pair\n",
    "of words that existed in the text. In the end, calculate the probability\n",
    "of each pair by conditional probability formula.\n",
    "\"\"\"\n",
    "\n",
    "def bigram(file_path: str, lines_count: int, words_count: dict):\n",
    "    global words\n",
    "    prob_dict = {}\n",
    "    with open(file_path, 'r', encoding='UTF_8') as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            words_line = line.split()\n",
    "            words_line.append(\"</s>\")\n",
    "            words_line.insert(0, \"<s>\")\n",
    "            for i in range(1, len(words_line)):\n",
    "                if words_line[i] not in words or words_line[i-1] not in words:\n",
    "                    continue\n",
    "                if (words_line[i], words_line[i-1]) not in prob_dict:\n",
    "                    prob_dict[(words_line[i], words_line[i-1])] = 1\n",
    "                else:\n",
    "                    prob_dict[(words_line[i], words_line[i-1])] += 1\n",
    "    \n",
    "    for pair in prob_dict:\n",
    "        if pair[1] != \"<s>\":\n",
    "            prob_dict[pair] /= words_count[pair[1]]\n",
    "        else:\n",
    "            prob_dict[pair] /= lines_count\n",
    "            \n",
    "    return prob_dict           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ferdowsi_bigram = bigram('ferdowsi_train.txt', ferdowsi_lines, ferdowsi_words)\n",
    "hafez_bigram = bigram('hafez_train.txt', hafez_lines, hafez_words)\n",
    "moalvi_bigram = bigram('molavi_train.txt', molavi_lines, molavi_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "This function receives unigram, bigram model, a line(list of words),\n",
    "and hyperparameters then calculate the probability of the line \n",
    "for the given model.\n",
    "\"\"\"\n",
    "\n",
    "def backoff_model(unigram: dict, bigram: dict, line : list, lambda3: int, lambda2: int, lambda1: int, epsilon: int):\n",
    "    probability = 1\n",
    "    \n",
    "    for i in range(1, len(line)):\n",
    "        bigram_prob = 0\n",
    "        unigram_prob = 0\n",
    "        \n",
    "        if (line[i], line[i-1]) in bigram:\n",
    "            bigram_prob = bigram[(line[i], line[i-1])]\n",
    "            \n",
    "        if line[i] in unigram:\n",
    "            unigram_prob = unigram[line[i]]\n",
    "        \n",
    "        probability *= (lambda3 * bigram_prob) + (lambda2 * unigram_prob) + (lambda1 * epsilon)\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ P\\left ( c_{i}\\mid c_{i-1}\\right ) = \\lambda _{3} P\\left ( c_{i}\\mid c_{i-1}\\right ) + \\lambda _{2} P\\left ( c_{i}\\right ) + \\lambda _{1}\\epsilon  $ <br><br>\n",
    "$ \\lambda_{1} + \\lambda_{2} + \\lambda_{3} = 1 $ <br><br>\n",
    "$ 0 < \\epsilon  < 1 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This function receives a text file path and hyperparameters.\n",
    "in the following, Calculate each line's probability by the backoff model,\n",
    "then specify the result by selecting the maximum value between three poets\n",
    "and comparing it to original poets, then calculate the model's absolute accuracy.\n",
    "\"\"\"\n",
    "\n",
    "def test(file_path: str, lambda3: int, lambda2: int, lambda1: int, epsilon: int):\n",
    "    correct_case = 0\n",
    "    total_case = 0\n",
    "    \n",
    "    with open(file_path, 'r', encoding='UTF_8') as f:\n",
    "        while True:   \n",
    "            result = 0\n",
    "            line = f.readline().split()\n",
    "            if not line:\n",
    "                break\n",
    "            line.append(\"</s>\")\n",
    "            line.insert(1, \"<s>\")\n",
    "            total_case += 1\n",
    "            ferdowsi_probability = backoff_model(ferdowsi_unigram, ferdowsi_bigram, line[1:], lambda3, lambda2, lambda1, epsilon)\n",
    "            hafez_probability = backoff_model(hafez_unigram, hafez_bigram, line[1:], lambda3, lambda2, lambda1, epsilon)\n",
    "            moalvi_probability = backoff_model(moalvi_unigram, moalvi_bigram, line[1:], lambda3, lambda2, lambda1, epsilon)\n",
    "            \n",
    "            if max(ferdowsi_probability, hafez_probability, moalvi_probability) == hafez_probability:\n",
    "                result = 2\n",
    "            elif max(ferdowsi_probability, hafez_probability, moalvi_probability) == moalvi_probability:\n",
    "                result = 3\n",
    "            elif max(ferdowsi_probability, hafez_probability, moalvi_probability) == ferdowsi_probability:\n",
    "                result = 1\n",
    "            if result == int(line[0]):\n",
    "                correct_case += 1\n",
    "    \n",
    "    return correct_case/total_case * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy1 = test('test_file.txt', lambda3=0.80, lambda2=0.18, lambda1=0.02, epsilon=0.000005)\n",
    "accuracy2 = test('test_file.txt', lambda3=0.95, lambda2=0.03, lambda1=0.02, epsilon=0.003)\n",
    "accuracy3 = test('test_file.txt', lambda3=0.80, lambda2=0.1998, lambda1=0.0002, epsilon=0.000005)\n",
    "accuracy4 = test('test_file.txt', lambda3=0.50, lambda2=0.20, lambda1=0.30, epsilon=0.00005)\n",
    "accuracy5 = test('test_file.txt', lambda3=0.70, lambda2=0.20, lambda1=0.10, epsilon=0.6)\n",
    "accuracy6 = test('test_file.txt', lambda3=0.90, lambda2=0.07, lambda1=0.03, epsilon=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t accuracy1 = 87.2093\n",
      "\t\t\t\t\t accuracy2 = 82.4128\n",
      "\t\t\t\t\t accuracy3 = 85.7558\n",
      "\t\t\t\t\t accuracy4 = 85.9375\n",
      "\t\t\t\t\t accuracy5 = 69.1497\n",
      "\t\t\t\t\t accuracy6 = 75.6904\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t\\t\\t\\t\\t accuracy1 = {0:.4f}\".format(accuracy1))\n",
    "print(\"\\t\\t\\t\\t\\t accuracy2 = {0:.4f}\".format(accuracy2))\n",
    "print(\"\\t\\t\\t\\t\\t accuracy3 = {0:.4f}\".format(accuracy3))\n",
    "print(\"\\t\\t\\t\\t\\t accuracy4 = {0:.4f}\".format(accuracy4))\n",
    "print(\"\\t\\t\\t\\t\\t accuracy5 = {0:.4f}\".format(accuracy5))\n",
    "print(\"\\t\\t\\t\\t\\t accuracy6 = {0:.4f}\".format(accuracy6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "### &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; <b>$ \\lambda_{1} $  = 0.02</b>\n",
    "###  &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; <b>$ \\lambda_{2} $  = 0.18</b>\n",
    "### &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; <b>$ \\lambda_{3} $  = 0.80</b>\n",
    "### &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; <b>$    \\epsilon  $  = 0.000005</b>\n",
    "<br><br>\n",
    "<font size=\"4\">As we see in the accuracy testing, it is essential to choose a small epsilon and lambda one value. If multiplying these values is significant, all probabilities calculated using the backoff model bios with a significant value that causes a reduction in total accuracy. About lambda two and lambda three, we know lambda three must be more significant than lambda two because bigram probability must have a greater portion in the backoff model. We use the above assignments to problem hyperparameters.</font>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
